{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Before usage of this API, \n",
    "please ensure the following packages are installed. \n",
    "\n",
    "Tensorflow: 1.11.0\n",
    "Keras: 2.2.4\n",
    "NumPy: 1.15.1\n",
    "\n",
    "Note that you can directly install these packages in ipython notebook\n",
    "through commands like \"!pip install tensorflow==1.11\"\n",
    "'''\n",
    "\n",
    "# Let's start our demestration\n",
    "# For this grid, we import some packages and utils.py\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import keras \n",
    "\n",
    "import random, math\n",
    "\n",
    "# You can use the API without creating an utils instance, \n",
    "# We create an utils instance here for printing some information \n",
    "# to illustrate that our operators function correctly \n",
    "import utils\n",
    "utils = utils.GeneralUtils()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_datas shape: (5000, 784)\n",
      "train_labels shape: (5000, 10)\n",
      "test_datas shape: (1000, 784)\n",
      "test_labels shape: (1000, 10)\n"
     ]
    }
   ],
   "source": [
    "# Prepare training dataset and untrained model for source-level mutation \n",
    "# Users can their our own dataset and model\n",
    "import network \n",
    "network = network.FCNetwork()\n",
    "\n",
    "# model is a simple FC(fully-connected) neural network\n",
    "# dataset is a subset from MNIST dataset with 5000 training data and 1000 testing data\n",
    "model = network.create_normal_FC_model()\n",
    "(train_datas, train_labels), (test_datas, test_labels) = network.load_data()\n",
    "\n",
    "print('train_datas shape:', train_datas.shape)\n",
    "print('train_labels shape:', train_labels.shape)\n",
    "print('test_datas shape:', test_datas.shape)\n",
    "print('test_labels shape:', test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of source-level mutation operators API\n",
    "import source_mut_operators\n",
    "source_mut_opts = source_mut_operators.SourceMutationOperators()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before DR\n",
      "Train data shape: (5000, 784)\n",
      "Train labels shape: (5000, 10)\n",
      "\n",
      "After DR, where the mutation ratio is 0.01\n",
      "Train data shape: (5050, 784)\n",
      "Train labels shape: (5050, 10)\n",
      "\n",
      "Before DR\n",
      "Train data shape: (5000, 784)\n",
      "Train labels shape: (5000, 10)\n",
      "\n",
      "After DR, where the mutation ratio is 0.1\n",
      "Train data shape: (5500, 784)\n",
      "Train labels shape: (5500, 10)\n",
      "\n",
      "Before DR\n",
      "Train data shape: (5000, 784)\n",
      "Train labels shape: (5000, 10)\n",
      "\n",
      "After DR, where the mutation ratio is 0.5\n",
      "Train data shape: (7500, 784)\n",
      "Train labels shape: (7500, 10)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# DR (Data Repetition), see https://github.com/KuoTzu-yang/DeepMutation for more explanation\n",
    "mutation_ratios = [0.01, 0.1, 0.5]\n",
    "for mutation_ratio in mutation_ratios:\n",
    "    \n",
    "    (DR_train_datas, DR_train_labels), DR_model = source_mut_opts.DR_mut((train_datas, train_labels), model, mutation_ratio)\n",
    "    utils.print_messages_SMO('DR', train_datas=train_datas, train_labels=train_labels, mutated_datas=DR_train_datas, mutated_labels=DR_train_labels, mutation_ratio=mutation_ratio)            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000\n",
      "Mutation ratio: 0.01\n",
      "Number of mislabeled labels: 50\n",
      "\n",
      "5000\n",
      "Mutation ratio: 0.1\n",
      "Number of mislabeled labels: 500\n",
      "\n",
      "5000\n",
      "Mutation ratio: 0.5\n",
      "Number of mislabeled labels: 2500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# LE (Label Error), see https://github.com/KuoTzu-yang/DeepMutation for more explanation\n",
    "mutation_ratios = [0.01, 0.1, 0.5]\n",
    "for mutation_ratio in mutation_ratios:\n",
    "    \n",
    "    (LE_train_datas, LE_train_labels), LE_model = source_mut_opts.LE_mut((train_datas, train_labels), model, 0, 9, mutation_ratio)\n",
    "    \n",
    "    mask_equal = LE_train_labels == train_labels\n",
    "    mask_equal = np.sum(mask_equal, axis=1) == 10\n",
    "    count_diff = len(train_labels) - np.sum(mask_equal)\n",
    "    print(len(train_labels))\n",
    "    print('Mutation ratio:', mutation_ratio)\n",
    "    print('Number of mislabeled labels:', count_diff)\n",
    "    print('')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before DM\n",
      "Train data shape: (5000, 784)\n",
      "Train labels shape: (5000, 10)\n",
      "\n",
      "After DM, where the mutation ratio is 0.01\n",
      "Train data shape: (4950, 784)\n",
      "Train labels shape: (4950, 10)\n",
      "\n",
      "Before DM\n",
      "Train data shape: (5000, 784)\n",
      "Train labels shape: (5000, 10)\n",
      "\n",
      "After DM, where the mutation ratio is 0.1\n",
      "Train data shape: (4500, 784)\n",
      "Train labels shape: (4500, 10)\n",
      "\n",
      "Before DM\n",
      "Train data shape: (5000, 784)\n",
      "Train labels shape: (5000, 10)\n",
      "\n",
      "After DM, where the mutation ratio is 0.5\n",
      "Train data shape: (2500, 784)\n",
      "Train labels shape: (2500, 10)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# DM (Data Missing), see https://github.com/KuoTzu-yang/DeepMutation for more explanation\n",
    "mutation_ratios = [0.01, 0.1, 0.5]\n",
    "for mutation_ratio in mutation_ratios:\n",
    "    \n",
    "    (DM_train_datas, DM_train_labels), DM_model = source_mut_opts.DM_mut((train_datas, train_labels), model, mutation_ratio)\n",
    "    \n",
    "    utils.print_messages_SMO('DM', train_datas=train_datas, train_labels=train_labels, mutated_datas=DM_train_datas, mutated_labels=DM_train_labels, mutation_ratio=mutation_ratio)            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "For DF, it's a little difficult to explicitly demonstrate\n",
    "a large amount of data samples be shuffled. \n",
    "Here, we simply illustrate how to use DF mutation operator.\n",
    "'''\n",
    "# DF (Data Shuffle), see https://github.com/KuoTzu-yang/DeepMutation for more explanation\n",
    "mutation_ratio = 0.01\n",
    "(DF_train_datas, DF_train_labels), DF_model = source_mut_opts.DF_mut((train_datas, train_labels), model, mutation_ratio)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A value in the first sample of original dataset -0.42343183542437446\n",
      "The value after NP mutation 1.004900489638712\n"
     ]
    }
   ],
   "source": [
    "# NP (Noise Perturb), see https://github.com/KuoTzu-yang/DeepMutation for more explanation\n",
    "mutation_ratio = 1\n",
    "STD = 1\n",
    "(NP_train_datas, NP_train_labels), NP_model = source_mut_opts.NP_mut((train_datas, train_labels), model, mutation_ratio, STD=STD)\n",
    "\n",
    "print('A value in the first sample of original dataset', train_datas[0][0])\n",
    "print('The value after NP mutation', NP_train_datas[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 64)                50240     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 16)                1040      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                170       \n",
      "=================================================================\n",
      "Total params: 51,994\n",
      "Trainable params: 51,994\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Before any mutation on model, let's see the architecture of this model. \n",
    "\n",
    "# According to the paper, there is a restriction of layer being added or removed.\n",
    "# The input and output shape of layer being added or removed are required to be same.\n",
    "\n",
    "# Hence, when you look at the architecture of this model. \n",
    "# There are layers with same input and output shape in this model for demenstration purpose.\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected layer by LR mutation operator 4\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1_copy_LR (Dense)      (None, 64)                50240     \n",
      "_________________________________________________________________\n",
      "dropout_1_copy_LR (Dropout)  (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2_copy_LR (Dense)      (None, 16)                1040      \n",
      "_________________________________________________________________\n",
      "dense_3_copy_LR (Dense)      (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_5_copy_LR (Dense)      (None, 10)                170       \n",
      "=================================================================\n",
      "Total params: 51,722\n",
      "Trainable params: 51,722\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# LR (Layer Removal), see https://github.com/KuoTzu-yang/DeepMutation for more explanation\n",
    "(LR_train_datas, LR_train_labels), LR_model = source_mut_opts.LR_mut((train_datas, train_labels), model)\n",
    "LR_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected layer by LAs mutation operator 3\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1_copy_LAs (Dense)     (None, 64)                50240     \n",
      "_________________________________________________________________\n",
      "dropout_1_copy_LAs (Dropout) (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2_copy_LAs (Dense)     (None, 16)                1040      \n",
      "_________________________________________________________________\n",
      "dense_3_copy_LAs (Dense)     (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "re_lu_1 (ReLU)               (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_4_copy_LAs (Dense)     (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_5_copy_LAs (Dense)     (None, 10)                170       \n",
      "=================================================================\n",
      "Total params: 51,994\n",
      "Trainable params: 51,994\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# LAs (Layer Addition for source-level mutation), see https://github.com/KuoTzu-yang/DeepMutation for more explanation\n",
    "(LAs_train_datas, LAs_train_labels), LAs_model = source_mut_opts.LAs_mut((train_datas, train_labels), model)\n",
    "LAs_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seleced layer by AFRs mutation operator 2\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "For AFRs, it's a little difficult to explicitly demonstrate\n",
    "Here, we simply illustrate how to use AFRs mutation operator.\n",
    "'''\n",
    "# AFRs (Activation Function Removal for source-level mutation), see https://github.com/KuoTzu-yang/DeepMutation for more explanation\n",
    "(AFRs_train_datas, AFRs_train_labels), AFRs_model = source_mut_opts.AFRs_mut((train_datas, train_labels), model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
